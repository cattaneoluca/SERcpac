{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "610106b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TESS&RAVDESS] There are 809 training audio files for category:angry\n",
      "[TESS&RAVDESS] There are 148 testing audio files for category:angry\n",
      "[TESS&RAVDESS] There are 806 training audio files for category:happy\n",
      "[TESS&RAVDESS] There are 148 testing audio files for category:happy\n",
      "[TESS&RAVDESS] There are 586 training audio files for category:neutral\n",
      "[TESS&RAVDESS] There are 94 testing audio files for category:neutral\n",
      "[TESS&RAVDESS] There are 813 training audio files for category:sad\n",
      "[TESS&RAVDESS] There are 147 testing audio files for category:sad\n",
      "[+] Writed TESS & RAVDESS DB CSV File\n",
      "[EMO-DB] Total files to write: 339\n",
      "[EMO-DB] Training samples: 271\n",
      "[EMO-DB] Testing samples: 67\n",
      "[+] Writed EMO-DB CSV File\n",
      "[Custom Dataset] There are 48 training audio files for category:happy\n",
      "[Custom Dataset] There are 23 testing audio files for category:happy\n",
      "[Custom Dataset] There are 49 training audio files for category:neutral\n",
      "[Custom Dataset] There are 33 testing audio files for category:neutral\n",
      "[Custom Dataset] There are 33 training audio files for category:sad\n",
      "[Custom Dataset] There are 33 testing audio files for category:sad\n",
      "[+] Writed Custom DB CSV File\n",
      "results/AHNS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "model loaded: results/AHNS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "[+] Data loaded\n"
     ]
    }
   ],
   "source": [
    "from deep_emotion_recognition_trained import DeepEmotionRecognizer\n",
    "# initialize instance\n",
    "# inherited from emotion_recognition.EmotionRecognizer\n",
    "# default parameters (LSTM: 128x2, Dense:128x2)\n",
    "network = DeepEmotionRecognizer(emotions=['angry', 'happy', 'neutral','sad'], n_rnn_layers=2, n_dense_layers=2, rnn_units=128, dense_units=128)\n",
    "\n",
    "# get the accuracy\n",
    "#print(deeprec.test_score())\n",
    "# predict angry audio sample\n",
    "#prediction = deeprec.predict('data/validation/Actor_10/03-02-05-02-02-02-10_angry.wav')\n",
    "#print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f180fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0.012038359, 'happy': 0.1863404, 'neutral': 0.022269364, 'sad': 0.77935183}\n"
     ]
    }
   ],
   "source": [
    "print(network.predict_proba(\"data/validation/Actor_10/03-02-02-01-02-02-10_calm.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ebbbf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def delete_folder_files(dir):\n",
    "\n",
    "    for f in os.listdir(dir):\n",
    "        os.remove(os.path.join(dir, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dfd7101",
   "metadata": {},
   "outputs": [],
   "source": [
    "### need os imported ###\n",
    "#import os\n",
    "\n",
    "def predict_emotions(dir):\n",
    "    predictions = []\n",
    "    for f in os.listdir(dir):\n",
    "        predictions.append(network.predict_proba(dir + '/' +f))\n",
    "        \n",
    "        #print(network.predict_proba(dir + '/' +f))\n",
    "        #print(dir + '/' + f)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "240ad43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyaudio\n",
    "import wave\n",
    "from array import array\n",
    "import struct\n",
    "import time\n",
    "\n",
    "\n",
    "def record(rate = 24414, chunk = 512, seconds = 5):\n",
    "    RATE = rate\n",
    "    CHUNK = chunk\n",
    "    RECORD_SECONDS = seconds\n",
    "    FORMAT = pyaudio.paInt32\n",
    "    CHANNELS = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "    \n",
    "    #Inizialize a non-silent signal array \n",
    "    data = array('h', np.random.randint(size = 512, low = 0, high = 500))\n",
    "    \n",
    "    #SESSION START\n",
    "    print(\"** session started\")\n",
    "    total_predictions = [] # A list for all predictions in the session.\n",
    "    tic = time.perf_counter()\n",
    "    \n",
    "    #while is_silent(data) == False:\n",
    "    for i in range(0,3):\n",
    "        print(\"* recording...\")\n",
    "        frames = [] \n",
    "        data = np.nan # Reset 'data' variable.\n",
    "\n",
    "        timesteps = int(RATE / CHUNK * RECORD_SECONDS) # => 339\n",
    "\n",
    "        # Insert frames to 'output.wav'.\n",
    "        for k in range(0, timesteps):\n",
    "            data = array('l', stream.read(CHUNK)) \n",
    "            frames.append(data)\n",
    "            \n",
    "            output_file = \"recordings/output\" + str(i) + \".wav\"\n",
    "            wf = wave.open(output_file, 'wb')\n",
    "            wf.setnchannels(CHANNELS)\n",
    "            wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "            wf.setframerate(RATE)\n",
    "            wf.writeframes(b''.join(frames))\n",
    "\n",
    "        print(\"* done recording\")\n",
    "        \n",
    "    print(\"** session ended\")\n",
    "    global is_recording\n",
    "    is_recording = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a39150e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** session started\n",
      "* recording...\n",
      "* done recording\n",
      "* recording...\n",
      "* done recording\n",
      "* recording...\n",
      "* done recording\n",
      "** session ended\n"
     ]
    }
   ],
   "source": [
    "delete_folder_files('recordings')\n",
    "\n",
    "record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d884fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'angry': 0.0011650968, 'happy': 0.09741572, 'neutral': 0.85697293, 'sad': 0.044446323}, {'angry': 0.00199729, 'happy': 0.25454012, 'neutral': 0.6790977, 'sad': 0.064364895}, {'angry': 0.1961456, 'happy': 0.2292252, 'neutral': 0.14974439, 'sad': 0.42488477}]\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_emotions('recordings')\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "375ad51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_average(results):\n",
    "    #instatiate averages vector\n",
    "    average_pred = {}\n",
    "    for emo in results[0]:\n",
    "        average_pred[emo] = 0\n",
    "    \n",
    "    length = len(results)\n",
    "    emo_num = len(results[0])\n",
    "    for emotion in results[0]:\n",
    "        for idx in range(0,length):\n",
    "            average_pred[emotion] += results[idx][emotion]\n",
    "        \n",
    "    for emotion in average_pred:\n",
    "        average_pred[emotion] /= length\n",
    "        \n",
    "    return average_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35afc60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0.06643599361026038, 'happy': 0.19372701396544775, 'neutral': 0.5619383454322815, 'sad': 0.1778986615439256}\n"
     ]
    }
   ],
   "source": [
    "pred = emotion_average(predictions)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53e6c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(network.predict_proba('brombeisMONO.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc1d858a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** session started\n",
      "* recording...\n",
      "* done recording\n",
      "* recording...\n",
      "* done recording\n",
      "* recording...\n",
      "* done recording\n",
      "** session ended\n",
      "** session started\n",
      "* recording...\n",
      "* done recording\n",
      "* recording...\n",
      "* done recording\n",
      "* recording...\n",
      "* done recording\n",
      "** session ended\n"
     ]
    }
   ],
   "source": [
    "import keyboard as kb\n",
    "is_recording = False\n",
    "\n",
    "while True:\n",
    "    if kb.is_pressed('space'):\n",
    "        if not is_recording:\n",
    "            is_recording = True\n",
    "            delete_folder_files('recordings')\n",
    "            record()\n",
    "            #print('A pressed \\n')\n",
    "    elif kb.is_pressed('Esc'): \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a697af1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
