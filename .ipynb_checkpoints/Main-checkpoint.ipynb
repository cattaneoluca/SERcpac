{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "610106b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TESS&RAVDESS] There are 809 training audio files for category:angry\n",
      "[TESS&RAVDESS] There are 148 testing audio files for category:angry\n",
      "[TESS&RAVDESS] There are 813 training audio files for category:sad\n",
      "[TESS&RAVDESS] There are 147 testing audio files for category:sad\n",
      "[TESS&RAVDESS] There are 586 training audio files for category:neutral\n",
      "[TESS&RAVDESS] There are 94 testing audio files for category:neutral\n",
      "[TESS&RAVDESS] There are 806 training audio files for category:happy\n",
      "[TESS&RAVDESS] There are 148 testing audio files for category:happy\n",
      "[+] Writed TESS & RAVDESS DB CSV File\n",
      "[EMO-DB] Total files to write: 339\n",
      "[EMO-DB] Training samples: 271\n",
      "[EMO-DB] Testing samples: 67\n",
      "[+] Writed EMO-DB CSV File\n",
      "[Custom Dataset] There are 49 training audio files for category:neutral\n",
      "[Custom Dataset] There are 33 testing audio files for category:neutral\n",
      "[Custom Dataset] There are 48 training audio files for category:happy\n",
      "[Custom Dataset] There are 23 testing audio files for category:happy\n",
      "[+] Writed Custom DB CSV File\n",
      "results/AHNS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "model loaded: results/AHNS-c-LSTM-layers-2-2-units-128-128-dropout-0.3_0.3_0.3_0.3.h5\n",
      "[+] Data loaded\n"
     ]
    }
   ],
   "source": [
    "from deep_emotion_recognition_trained import DeepEmotionRecognizer\n",
    "# initialize instance\n",
    "# inherited from emotion_recognition.EmotionRecognizer\n",
    "# default parameters (LSTM: 128x2, Dense:128x2)\n",
    "network = DeepEmotionRecognizer(emotions=['angry', 'sad', 'neutral', 'happy'], n_rnn_layers=2, n_dense_layers=2, rnn_units=128, dense_units=128)\n",
    "\n",
    "# get the accuracy\n",
    "#print(deeprec.test_score())\n",
    "# predict angry audio sample\n",
    "#prediction = deeprec.predict('data/validation/Actor_10/03-02-05-02-02-02-10_angry.wav')\n",
    "#print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f180fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0.010557492, 'sad': 0.22484453, 'neutral': 0.76254386, 'happy': 0.0020541605}\n"
     ]
    }
   ],
   "source": [
    "print(network.predict_proba(\"data/validation/Actor_10/03-02-02-01-02-02-10_calm.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ebbbf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def delete_folder_files(dir):\n",
    "\n",
    "    for f in os.listdir(dir):\n",
    "        os.remove(os.path.join(dir, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dfd7101",
   "metadata": {},
   "outputs": [],
   "source": [
    "### need os imported ###\n",
    "#import os\n",
    "\n",
    "def predict_emotions(dir):\n",
    "    \n",
    "    for f in os.listdir(dir):\n",
    "        print(network.predict_proba(dir + '/' +f))\n",
    "        #print(dir + '/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "240ad43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyaudio\n",
    "import wave\n",
    "from array import array\n",
    "import struct\n",
    "import time\n",
    "\n",
    "def record(rate = 24414, chunk = 512, seconds = 5):\n",
    "    RATE = rate\n",
    "    CHUNK = chunk\n",
    "    RECORD_SECONDS = seconds\n",
    "    FORMAT = pyaudio.paInt32\n",
    "    CHANNELS = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "    \n",
    "    #Inizialize a non-silent signal array \n",
    "    data = array('h', np.random.randint(size = 512, low = 0, high = 500))\n",
    "    \n",
    "    #SESSION START\n",
    "    print(\"** session started\")\n",
    "    total_predictions = [] # A list for all predictions in the session.\n",
    "    tic = time.perf_counter()\n",
    "    \n",
    "    #while is_silent(data) == False:\n",
    "    for i in range(0,3):\n",
    "        print(\"* recording...\")\n",
    "        frames = [] \n",
    "        data = np.nan # Reset 'data' variable.\n",
    "\n",
    "        timesteps = int(RATE / CHUNK * RECORD_SECONDS) # => 339\n",
    "\n",
    "        # Insert frames to 'output.wav'.\n",
    "        for k in range(0, timesteps):\n",
    "            data = array('l', stream.read(CHUNK)) \n",
    "            frames.append(data)\n",
    "            \n",
    "            output_file = \"recordings/output\" + str(i) + \".wav\"\n",
    "            wf = wave.open(output_file, 'wb')\n",
    "            wf.setnchannels(CHANNELS)\n",
    "            wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "            wf.setframerate(RATE)\n",
    "            wf.writeframes(b''.join(frames))\n",
    "\n",
    "        print(\"* done recording\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a39150e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** session started\n",
      "* recording...\n",
      "* done recording\n",
      "* recording...\n",
      "* done recording\n",
      "* recording...\n",
      "* done recording\n"
     ]
    }
   ],
   "source": [
    "delete_folder_files('recordings')\n",
    "\n",
    "record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d884fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0.004095483, 'sad': 0.16830863, 'neutral': 0.82609385, 'happy': 0.0015020166}\n",
      "{'angry': 0.078271, 'sad': 0.006695103, 'neutral': 0.9143157, 'happy': 0.00071820023}\n",
      "{'angry': 0.050721515, 'sad': 0.020076733, 'neutral': 0.9276138, 'happy': 0.0015879455}\n"
     ]
    }
   ],
   "source": [
    "predict_emotions('recordings')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53e6c731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0.012996169, 'sad': 0.53388846, 'neutral': 0.45148727, 'happy': 0.0016280705}\n"
     ]
    }
   ],
   "source": [
    "print(network.predict_proba('brombeisMONO.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8722164c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
